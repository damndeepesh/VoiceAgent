<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Riverwood Voice Agent - Direct Web Voice</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: Arial, sans-serif; margin: 40px auto; max-width: 520px; color: #1f2933; }
    h1 { font-size: 1.8rem; }
    .center { display: flex; align-items: center; justify-content: center; }
    .blob {
      width: 140px; height: 140px; border-radius: 50%;
      background: radial-gradient( circle at 30% 30%, #60a5fa, #1d4ed8 );
      box-shadow: 0 10px 30px rgba(29,78,216,0.35);
      transition: transform 0.2s ease;
    }
    .blob.listening { animation: pulse 1.2s ease-in-out infinite; }
    @keyframes pulse {
      0% { transform: scale(1); }
      50% { transform: scale(1.08); }
      100% { transform: scale(1); }
    }
    .controls { margin-top: 24px; display: flex; gap: 12px; justify-content: center; }
    button {
      padding: 12px 18px; border: none; border-radius: 8px; color: #fff; cursor: pointer;
      background: #2563eb;
    }
    button.alt { background: #6b7280; }
    button:disabled { opacity: 0.6; cursor: not-allowed; }
    .status { margin-top: 20px; padding: 12px; background: #f5f7fa; border-radius: 6px; min-height: 60px; white-space: pre-wrap; }
    .row { margin-top: 14px; display: flex; gap: 10px; }
    input, select { flex: 1; padding: 10px; border: 1px solid #cbd2d9; border-radius: 6px; }
    audio { width: 100%; margin-top: 12px; }
  </style>
</head>
<body>
  <h1>Riverwood Voice Agent (Direct Web Voice)</h1>
  <p>Click “Hold to Talk” to record a message. On release, your speech is transcribed, the agent replies, and audio plays back—no phone number required.</p>

  <div class="center">
    <div id="blob" class="blob"></div>
  </div>

  <div class="controls">
    <button id="toggle-btn">Start Conversation</button>
    <button id="stop-btn" class="alt" disabled>Stop</button>
    <button id="rt-start" class="alt">Start Realtime (beta)</button>
    <button id="rt-flush" class="alt" disabled>Send</button>
    <button id="rt-stop" class="alt" disabled>Stop Realtime</button>
  </div>

  <div class="row">
    <input id="session" placeholder="Session ID (auto)" />
    <select id="lang">
      <option value="hi">Hindi (hi)</option>
      <option value="en">English (en)</option>
    </select>
  </div>

  <div class="status" id="status">Idle.</div>
  <audio id="player" controls></audio>

  <script>
    const statusEl = document.getElementById('status');
    const blobEl = document.getElementById('blob');
    const toggleBtn = document.getElementById('toggle-btn');
    const stopBtn = document.getElementById('stop-btn');
    const rtStartBtn = document.getElementById('rt-start');
    const rtFlushBtn = document.getElementById('rt-flush');
    const rtStopBtn = document.getElementById('rt-stop');
    const player = document.getElementById('player');
    const sessionInput = document.getElementById('session');
    const langSel = document.getElementById('lang');

    let mediaRecorder = null;
    let chunks = [];
    let conversationActive = false;
    let recordingTimer = null;
    const CHUNK_MS = 4000; // record in ~4s chunks for turn-taking
    // Realtime WS
    let ws = null;
    let rtRecorder = null;
    let rtStream = null;

    function log(msg) { statusEl.textContent = msg; }

    function ensureSession() {
      let sid = sessionStorage.getItem('riverwood_session');
      if (!sid) {
        sid = 'web-' + Math.random().toString(16).slice(2);
        sessionStorage.setItem('riverwood_session', sid);
      }
      sessionInput.value = sessionInput.value || sid;
      return sessionInput.value;
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        chunks = [];
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
        mediaRecorder.ondataavailable = e => { if (e.data.size > 0) chunks.push(e.data); };
        mediaRecorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });
          await sendForProcessing(blob);
          stream.getTracks().forEach(t => t.stop());
        };
        mediaRecorder.start();
        blobEl.classList.add('listening');
        stopBtn.disabled = false;
        log('Listening…');
        // Auto-stop after CHUNK_MS to simulate a turn
        clearTimeout(recordingTimer);
        recordingTimer = setTimeout(() => {
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
        }, CHUNK_MS);
      } catch (err) {
        log('Microphone error: ' + err.message);
      }
    }

    async function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        blobEl.classList.remove('listening');
        stopBtn.disabled = true;
        log('Processing…');
      }
    }

    async function sendForProcessing(blob) {
      try {
        const fd = new FormData();
        fd.append('audio', blob, 'speech.webm');
        fd.append('session', ensureSession());
        fd.append('lang', langSel.value);
        const resp = await fetch('/direct/stt-llm-tts', { method: 'POST', body: fd });
        if (!resp.ok) {
          const txt = await resp.text().catch(() => '');
          log('Server error: ' + txt);
          return;
        }
        const contentType = resp.headers.get('content-type') || '';
        if (contentType.includes('application/json')) {
          const data = await resp.json();
          if (data.text) {
            log('Reply (browser TTS fallback).');
            speakLocally(data.text);
          } else {
            log('Received empty JSON response.');
          }
          return;
        }
        const audioBlob = await resp.blob();
        player.src = URL.createObjectURL(audioBlob);
        log('Reply playing.');
        // Pause conversation recording during playback to avoid feedback
        player.onended = () => {
          if (conversationActive) {
            // start next user turn automatically
            startRecording();
          } else {
            log('Idle.');
          }
        };
        await player.play().catch(() => {});
      } catch (err) {
        log('Failed to process: ' + err.message);
      }
    }

    function speakLocally(text) {
      if (!window.speechSynthesis) {
        log('Browser TTS not supported.');
        return;
      }
      const utt = new SpeechSynthesisUtterance(text);
      utt.lang = langSel.value === 'hi' ? 'hi-IN' : 'en-IN';
      speechSynthesis.cancel();
      speechSynthesis.speak(utt);
    }

    stopBtn.addEventListener('mouseup', stopRecording);
    stopBtn.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); }, { passive: false });

    // Toggle continuous to-and-fro loop
    toggleBtn.addEventListener('click', async () => {
      conversationActive = !conversationActive;
      toggleBtn.textContent = conversationActive ? 'Stop Conversation' : 'Start Conversation';
      if (conversationActive) {
        log('Conversation started. Listening…');
        await startRecording();
      } else {
        clearTimeout(recordingTimer);
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          mediaRecorder.stop();
        }
        try { player.pause(); } catch {}
        blobEl.classList.remove('listening');
        log('Conversation stopped.');
      }
    });

    // Realtime beta using MediaRecorder timeslices over WebSocket
    async function startRealtime() {
      try {
        ws = new WebSocket((location.protocol === 'https:' ? 'wss://' : 'ws://') + location.host + '/direct/stream');
        ws.onopen = () => {
          ws.send(JSON.stringify({ type: 'start', session: ensureSession(), lang: langSel.value }));
          log('Realtime connected. Speak freely, then press Send to get a reply.');
          rtStartBtn.disabled = true;
          rtFlushBtn.disabled = false;
          rtStopBtn.disabled = false;
        };
        ws.onmessage = (ev) => {
          try {
            const msg = JSON.parse(ev.data);
            if (msg.type === 'partial') {
              // Optionally show partials
              // log('Partial: ' + msg.text);
            } else if (msg.type === 'reply_audio_url') {
              player.src = msg.url;
              player.play().catch(()=>{});
              log('Reply playing.');
            } else if (msg.type === 'reply_text') {
              speakLocally(msg.text);
              log('Reply (browser TTS).');
            }
          } catch {}
        };
        ws.onclose = () => {
          rtStartBtn.disabled = false;
          rtFlushBtn.disabled = true;
          rtStopBtn.disabled = true;
          log('Realtime disconnected.');
        };
        rtStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        rtRecorder = new MediaRecorder(rtStream, { mimeType: 'audio/webm' });
        rtRecorder.ondataavailable = async (e) => {
          if (e.data && e.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {
            const buf = await e.data.arrayBuffer();
            const b64 = btoa(String.fromCharCode(...new Uint8Array(buf)));
            ws.send(JSON.stringify({ type: 'audio', b64 }));
          }
        };
        rtRecorder.start(1000); // send ~1s chunks
      } catch (err) {
        log('Realtime error: ' + err.message);
      }
    }
    function flushRealtime() {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'flush' }));
        log('Thinking…');
      }
    }
    function stopRealtime() {
      try {
        if (rtRecorder && rtRecorder.state !== 'inactive') rtRecorder.stop();
      } catch {}
      try {
        if (rtStream) rtStream.getTracks().forEach(t => t.stop());
      } catch {}
      try {
        if (ws && ws.readyState === WebSocket.OPEN) ws.send(JSON.stringify({ type: 'stop' }));
      } catch {}
      try {
        if (ws) ws.close();
      } catch {}
    }
    rtStartBtn.addEventListener('click', startRealtime);
    rtFlushBtn.addEventListener('click', flushRealtime);
    rtStopBtn.addEventListener('click', stopRealtime);
  </script>
</body>
</html>

